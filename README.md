# self-updating-DT-model-by-online-deep-learning

|    Models    |                                                                                                                                                                 Model setting                                                                                                                                                                |
|:------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
|      MLP     |                                                                  An input layer with dimensions [11, 50], two hidden layers with dimensions [50, 50], and one output layer with dimensions [50, 1].The Adam optimization method is employed with a learning rate of 0.001.                                                                   |
|     LSTM     |                                                                                          An LSTM layer with dimensions [11, 50] and a linear layer with dimensions [50, 1]. The Adam optimization method is employed with a learning rate of 0.001.                                                                                          |
|  Transformer | An input embedding layer with dimensions [11, 500], a positional encoding layer with dimensions 400, two transformer encoding layers (400 dimensions, 10 attention heads, and a dropout probability of 0.1), and a linear decoder layer with dimensions [400, 1].  The AdamW optimization method is employed with a learning rate of 0.005.  |
|  Online MLP  |                                                                                                                                      The neural network and learning method are aligned with MLP method.                                                                                                                                     |
|     OSELM    |                                                                                                                           The random layer comprises 70 hidden units, employing the "sigmoid" activation function.                                                                                                                           |
| SRPRegressor |                                                                                                                                                 The number of members in the ensemble are 20.                                                                                                                                                |
| OXTRegressor |                                                                                                                                                  The number of trees in the ensemble are 20.                                                                                                                                                 |
|  Online LSTM |                                                                                                                     The neural network is aligned with LSTM method. The learning method is SGD and learning rate is 0.01                                                                                                                     |
